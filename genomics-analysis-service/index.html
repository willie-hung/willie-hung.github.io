<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Genomics Analysis Service</title>
    <link rel="icon" href="./img/dna.ico" type="image/x-icon" />
    <link rel="stylesheet" href="./main.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/devicons/devicon@v2.15.1/devicon.min.css"
    />
  </head>
  <body>
    <section class="section">
      <div class="container">
        <div class="level">
          <div
            class="level-item is-flex is-flex-direction-row is-justify-content-center is-align-items-center"
          >
            <figure class="image">
              <image width="20px" src="./img/dna-3.png" />
            </figure>
            <h1 class="title has-text-centered">
              &nbsp Genomics Analysis Service
            </h1>
          </div>
        </div>

        <hr />

        <div class="content">
          <h2>üéØ Overview</h2>
          <p>
            A fully operational software-as-a-service(SaaS) for genomics
            analysis.
          </p>
        </div>

        <div class="content">
          <h4>Tech Stack</h4>
          <div
            class="is-flex is-flex-direction-row is-flex-wrap-wrap is-justify-content-center is-align-items-baseline"
          >
            <div>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg"
                  />
                </span>
                <span>Python</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/flask/flask-original.svg"
                  />
                </span>
                <span>Flask</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/amazonwebservices/amazonwebservices-original.svg"
                  />
                </span>
                <span>AWS</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/postgresql/postgresql-original.svg"
                  />
                </span>
                <span>PostgreSQL</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/javascript/javascript-original.svg"
                  />
                </span>
                <span>JavaScript</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg"
                  />
                </span>
                <span>HTML</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/css3/css3-original.svg"
                  />
                </span>
                <span>CSS</span>
              </button>
              <button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bootstrap/bootstrap-original.svg"
                  />
                </span>
                <span>Bootstrap</span>
              </button>
            </div>
          </div>

          <h4 id="diagram">Diagram</h4>

          <div class="box">
            <div
              class="is-flex is-justify-content-center is-align-items-center"
            >
              <figure class="image column is-two-thirds">
                <image src="./img/overview.jpg" />
              </figure>
            </div>
          </div>
        </div>

        <div class="content pt-4">
          <h2>‚öôÔ∏è Environment Setup</h2>
          <div class="box is-justify-content-center">
            <ul>
              <li>
                <a
                  href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html"
                  target="_blank"
                  >AWS Command Line Interface</a
                >
              </li>
              <li>
                <a
                  href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
                  target="_blank"
                  >AWS SDK for Python (boto3)</a
                >
              </li>
              <li>
                <a href="https://aws.amazon.com/" target="_blank">
                  AWS Cloud Computing Services</a
                >
              </li>
            </ul>
          </div>
        </div>

        <div class="content pt-4">
          <h2>üî® Building Process</h2>
          <h4>1Ô∏è‚É£ Building the Annotator API</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Build an API for accessing cloud-hosted computing service (AWS).
            </p>

            <h5>What is annotation?</h5>
            <p>
              Annotation is a crucial procedure that involves the analysis of a
              sequenced genome sample to pinpoint the precise locations of genes
              and coding regions within the genome. Its primary objective is to
              unravel the functions and characteristics of these genes,
              providing invaluable insights into their roles and activities.
            </p>

            <h5>The science behind genome annotation</h5>
            <p>
              <a
                href="https://www.ncbi.nlm.nih.gov/books/NBK20253/"
                target="_blank"
                ><span class="tag is-link is-light">Link</span></a
              >
            </p>

            <h5>AnnTool</h5>
            <p>
              I utilize
              <a href="https://anntools.sourceforge.net/" target="_blank"
                >AnnTools</a
              >
              and
              <a
                href="https://github.com/DipanshuSehjal/anntools"
                target="_blank"
                >this modified version</a
              >, one of the many available open source annotations tools, to
              perform the analysis.
            </p>

            <h5>Flask framework</h5>
            <p>
              An application server that can accept HTTP requests and server
              responses. I use the
              <a
                href="https://flask.palletsprojects.com/en/2.3.x/"
                target="_blank"
                >Flask Python web microframework</a
              >
              to implement the annotator API.
            </p>

            <h5>REST APIs (Sample endpoints)</h5>
            <p>
              Implement a service with an API that allows users to run
              annotation jobs and check on their status.
            </p>
            <ul>
              <li>
                <p>
                  <span class="tag is-primary is-light">GET</span>
                </p>
                <ul>
                  <li>
                    <p>
                      <strong>Endpoint:</strong>
                      http://{DOMAIN}/annotations/{job_id}
                    </p>
                  </li>
                  <li>
                    <strong>Response data:</strong>
                  </li>
                  <ul>
                    <li>
                      code (HTTP response code, integer) and status (‚Äúsuccess‚Äù
                      or ‚Äúerror‚Äù)
                    </li>
                    <li>job_id (UUID, string)</li>
                    <li>job_status (string)</li>
                    <li>
                      log (contents of log file for completed job, string)
                    </li>
                  </ul>
                </ul>
                <hr />
                <ul>
                  <li>
                    <p>
                      <strong>Endpoint:</strong> http://{DOMAIN}/annotations
                    </p>
                  </li>
                  <li>
                    <strong>Response data:</strong>
                  </li>
                  <ul>
                    <li>
                      code (HTTP response code, integer) and status (‚Äúsuccess‚Äù
                      or ‚Äúerror‚Äù)
                    </li>
                    <li>jobs (list of jobs)</li>
                    <ul>
                      <li>job_id (UUID, string)</li>
                      <li>
                        job_details (URL to get job status via endpoint above)
                      </li>
                    </ul>
                  </ul>
                </ul>
              </li>

              <li><span class="tag is-warning is-light">POST</span></li>
              <ul>
                <li>
                  <p><strong>Endpoint:</strong> http://{DOMAIN}/annotations</p>
                </li>
                <li>
                  <strong>Request body:</strong>
                  input_file (string)
                </li>
                <li>
                  <strong>Response data:</strong>
                </li>
                <ul>
                  <li>
                    code (HTTP response code, integer) and status (‚Äúsuccess‚Äù or
                    ‚Äúerror‚Äù)
                  </li>
                  <li>job_id (UUID, string)</li>
                  <li>input_file (string)</li>
                </ul>
              </ul>
            </ul>

            <h5>Running Environment</h5>
            <p>
              Both AnnTool and the API server are running on
              <a
                href="https://aws.amazon.com/ec2/getting-started/"
                target="_blank"
                >AWS EC2 instances</a
              >.
            </p>

            <h5>Test the API</h5>
            <p>
              Utilize
              <a href="https://www.postman.com/" target="_blank">Postman</a> to
              submit request data and view responses.
            </p>
          </div>

          <h4>2Ô∏è‚É£ Uploading Data to Object Storage: Amazon S3</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              To become familiar with object storage and authenticated calls
              (signed requests) to the cloud API.
            </p>
            <h5>Approach</h5>
            <p>
              Utilize <a href="#diagram">2 Amazon S3 buckets</a> to store user
              input files and annotated result files.
            </p>
            <h5>Working with large files</h5>
            <p>
              S3 provides a way for developers to upload large files directly
              from a web browser. It requires that we create a signed request
              and POST that request to the URL of our S3 bucket. The S3 service
              then takes over and uploads the file directly via the browser,
              bypassing our app server.
            </p>
            <h5>Protect your credentials</h5>
            <h6>Signed requests</h6>
            <p>
              For signed requests, AWS supports two types of signatures. When
              you refer to documentation on working with signed requests make
              sure it pertains to Version 4 signatures. To Learn more about
              signed requests, see the
              <a
                href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-UsingHTTPPOST.html"
                target="_blank"
                >AWS documentation here</a
              >.
            </p>
            <h6>Instance profile</h6>
            <p>
              Launch instances with a special type of permission attached, and
              boto3 will automagically find and use your credentials on the
              instance. This is a more secure approach, because keys are not
              physically stored on the instance and AWS automatically refreshes
              (i.e. expires and renews) these temporary keys as needed. In order
              to enable this, I launch instances and attach an
              <a
                href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html#ec2-instance-profile"
                target="_blank"
                >instance profile</a
              >
              to the instance; this profile includes permissions in the form of
              an instance role that will allow applications running on the
              instance to access other AWS resources on your behalf.
            </p>
            <h5>
              Add new endpoints (I will not specify all the endpoints in future
              steps)
            </h5>

            <ul>
              <li><span class="tag is-warning is-light">POST</span></li>
              <ul>
                <li>
                  <p><strong>Endpoint:</strong> http://{DOMAIN}/annotate</p>
                </li>
                <li>
                  <strong>Purpose:</strong>
                  User will navigate to this endpoint, browse and select a file,
                  and click the button to upload it to the S3 bucket.
                </li>
                <li>
                  <strong>Important:</strong>
                  Must contain an expiration timestamp. This is a critical part
                  of a signed request: the request must be completed before the
                  specified time otherwise it is rendered invalid. Furthermore,
                  the policy document must, at minimum, contain conditions for
                  the ACL, which is critical for security.
                </li>
              </ul>

              <li><span class="tag is-primary is-light">GET</span></li>
              <ul>
                <li>
                  <p>
                    <strong>Endpoint:</strong> http://{DOMAIN}/annotate/files
                  </p>
                </li>
                <li>
                  <strong>Purpose:</strong>
                  Gets a list of objects from your S3 input bucket and returns
                  them in a JSON object:
                </li>
              </ul>
            </ul>
          </div>

          <h4>3Ô∏è‚É£ Application Decoupling - Front/Back-End Separation</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Building out the distributed infrastructure for this genome
              annotation service.
            </p>
            <h5 id="step3-diagram">Diagram</h5>
            <div
              class="is-flex is-justify-content-center is-align-items-center"
            >
              <figure class="image column is-two-thirds">
                <image src="./img/step3.jpg" />
              </figure>
            </div>
            <h5>Approach</h5>
            <p>
              Utilize
              <a href="#step3-diagram">two EC2 instances</a>: one running the
              web application server and the other running the annotation
              server.
            </p>
            <ul>
              <li>
                Separate the code that serves the user interface from the code
                that implements the API and runs AnnTools.
              </li>
              <li>
                <u>annotator.py</u>: it downloads the input file from S3 and
                saves it to the AnnTools instance (into a file structure that
                ensures uniqueness for multiple jobs running simultaneously).
              </li>
              <li>
                <u>run.py</u>: after completion, it copies the annotated results
                file and the associated log from the local volume on your
                annotator instance to the S3 results bucket. After copying, the
                local files on the AnnTools instance must be deleted (otherwise
                the EBS volume attached to your instance would eventually run
                out of space).
              </li>
            </ul>
            <h5>The application flow till now</h5>
            <ul>
              <li>The user requests an annotation by uploading a VCF file.</li>
              <li>
                After the input file is uploaded to S3, the response is
                redirected to the annotator instance (and the flow continues
                there instead of on our web server).
              </li>
              <li>
                The annotator then downloads the input file from the input S3
                bucket, spawns the annotation job and returns the job_id and
                file name to the user.
              </li>
              <li>
                Once the annotation is complete, the results file and the log
                file are moved to the S3 results bucket.
              </li>
            </ul>
          </div>

          <h4>4Ô∏è‚É£ Persisting Data in a Key-Value Store</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Add persistence that enables distributed services to operate with
              greater durability.
            </p>
            <h5 id="step4-diagram">Diagram</h5>
            <div
              class="is-flex is-justify-content-center is-align-items-center"
            >
              <figure class="image column is-two-thirds">
                <image src="./img/step4.jpg" />
              </figure>
            </div>
            <h5>Approach</h5>
            <p>
              We are adding a key-value store (KVS) to persist annotation job
              information and allow both services to access/update a job as its
              status changes. We will use
              <a href="https://aws.amazon.com/dynamodb/" target="_blank"
                >DynamoDB</a
              >
              for this purpose. We‚Äôre using a KVS because we assert that
              annotation data will be irregular and hence better suited to a
              schema-less database.
            </p>
            <h5>The application flow till now</h5>
            <ul>
              <li>
                User selects an input file which is uploaded to S3 via a signed
                POST request.
              </li>
              <li>
                S3 sends a request to the redirect URL which must now be handled
                by our web app, and not by the annotator.
              </li>
              <li>
                The web app creates an item in the database; sets status to
                ‚ÄúPENDING‚Äù.
              </li>
              <li>The web app POSTs a request to the annotator.</li>
              <li>The annotator downloads the input file from S3.</li>
              <li>
                The annotator spawns the annotation and updates the job‚Äôs status
                to ‚ÄúRUNNING‚Äù.
              </li>
              <li>The annotator copies the result and log files to S3.</li>
              <li>
                The annotator again updates the job‚Äôs status in the database to
                ‚ÄúCOMPLETED‚Äù.
              </li>
            </ul>
          </div>
          <h4>5Ô∏è‚É£ Application Decoupling Using Message Queues</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Use inter-process communication services to allow services to
              operate asynchronously (thereby increasing system availability)
              and scale independently.
            </p>
            <h5 id="step5-diagram">Diagram</h5>
            <div
              class="is-flex is-justify-content-center is-align-items-center"
            >
              <figure class="image column is-two-thirds">
                <image src="./img/step5.jpg" />
              </figure>
            </div>
            <h5>Approach</h5>
            <p>
              In previous step 4Ô∏è‚É£ , we added a key-value store as the
              persistence layer for the service. This allowed the web server and
              the annotation server to operate independently of each other. Now
              we will add components that further decouple the services and
              allow them each to scale independently of the other.
            </p>
            <h6>
              Message Queue:
              <a href="https://aws.amazon.com/sqs/" target="_blank">AWS SQS</a>
            </h6>
            <p>
              A message queue that will act as a ‚Äúbuffer‚Äù between the web app
              and the annotator. New annotation requests will be posted to the
              message queue and the annotator will retrieve them independently.
              Thus, requests can be successfully accepted by this service, even
              if the annotator service is not available‚Äîan important requirement
              for increasing the availability of a distributed system.
            </p>
            <h6>
              Notification Topic:
              <a href="https://aws.amazon.com/sns/" target="_blank">AWS SNS</a>
            </h6>
            <p>
              A notification topic that accepts messages (i.e. annotation
              requests) from the web app. When a notification is sent to the
              topic, a message will be created in the message queue.
            </p>
            <h5>The application flow till now</h5>
            <ul>
              <li>
                User selects an input file which is uploaded to S3 via a signed
                POST request.
              </li>
              <li>S3 sends a request to the redirect URL in our web app.</li>
              <li>
                The web app posts a notification message containing the request
                data to the SNS topic.
              </li>
              <li>
                The SQS queue receives the notification and persists a message
                containing the request.
              </li>
              <li>The annotator reads the message from the SQS queue.</li>
              <li>
                The annotator extracts the input file name from the message and
                downloads it from S3.
              </li>
              <li>
                The annotator updates the job‚Äôs status in the database and
                spawns the annotation.
              </li>
              <li>The annotator copies the result and log files to S3.</li>
              <li>
                The annotator again updates the job‚Äôs status in the database.
              </li>
            </ul>

            <h5>Important</h5>
            <p>
              For current approach, we utilize a Python script and
              <a
                href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-short-and-long-polling.html"
                target="_blank"
                >long polling</a
              >
              to read the messages from queue. In the future, we will utilize
              <a href="#step7">webhooks</a> to get the messages from queue.
            </p>
          </div>

          <h4>6Ô∏è‚É£ Integrate Third-party Services and other system components</h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Make the system more functionally complete, integrate with an
              external cloud service for payments processing (<a
                href="https://stripe.com/"
                target="_blank"
                >Stripe</a
              >), and enable automated scaling. Furthermore, apply asynchronous
              communication to another part of the application by implementing a
              notifications service in upcoming steps.
            </p>
            <h5>Add Key functions</h5>
            <ul>
              <li>
                <strong
                  >Log in (<a
                    href="https://docs.globus.org/api/auth/"
                    target="_blank"
                    >via Globus Auth</a
                  >) to use this service</strong
                >: Some aspects of the service are available only to registered
                users. Two classes of users will be supported: <u>Free</u> and
                <u>Premium</u>. Premium users will have access to additional
                functionality, beyond that available to Free users.
              </li>
              <li>
                <strong>Submit an annotation job</strong>: Free users may only
                submit jobs of up to a certain size. Premium users may submit
                any size job. If a Free user submits an oversized job, the
                system will refuse it and will prompt the user to convert to a
                Premium user.
              </li>
              <li>
                <strong>Upgrade from a Free to a Premium user</strong>: Premium
                users will be required to provide a credit card for payment of
                the service subscription. Thise service will integrate with
                <a href="https://stripe.com/docs/api" target="_blank">Stripe</a>
                for credit card payment processing.
              </li>
              <li>
                <strong
                  >Receive notifications when annotation jobs finish</strong
                >
                : When their annotation request is complete, this service will
                send users an email that includes a link where they can view the
                log file and download the results file.
              </li>
              <li>
                <strong>Browse jobs and download annotation results</strong>:
                This service will store annotation results for later retrieval.
                Users may view a list of their jobs (completed and running), and
                the log file for completed jobs.
              </li>
              <li>
                <strong>Restrict data access for Free users</strong>: Free users
                may download their results file for a limited time after their
                job completes; thereafter the results file is archived, and only
                available to them if they convert to a Premium user. Premium
                users will always have all their data available for download.
              </li>
            </ul>
            <h5>Add and migrate system components</h5>
            <ul>
              <li>
                <strong
                  ><a href="https://docs.globus.org/api/auth/" target="_blank"
                    >Globus Auth</a
                  ></strong
                >: Globus Auth is an identity and access management service that
                allows users to access our application using an existing
                identity from thousands of identity providers, including
                UChicago.
              </li>
              <li>
                <strong
                  ><a
                    href="https://uwsgi-docs.readthedocs.io/en/latest/"
                    target="_blank"
                    >uWSGI</a
                  ></strong
                >: Substitute the default Flask WSGI server with the uWSGI
                server which is a well-tested, multithreaded WSGI server
                suitable for production use. Furthermore, our application will
                now listen on port 4433 instead of 5000.
              </li>
              <li>
                <strong
                  ><a href="https://en.wikipedia.org/wiki/HTTPS" target="_blank"
                    >HTTPS</a
                  ></strong
                >: The web server will now respond only to HTTPS requests.
              </li>
              <li>
                <strong
                  ><a
                    href="https://aws.amazon.com/s3/storage-classes/glacier/"
                    target="_blank"
                    >AWS S3 Glacier</a
                  ></strong
                >: A low cost, highly-durable object store for archiving the
                data of Free users.
              </li>
              <li>
                <strong
                  ><a href="https://www.postgresql.org/" target="_blank"
                    >PostgreSQL</a
                  ></strong
                >: A relational database for user account information.
              </li>
              <li>
                <strong
                  ><a href="https://getbootstrap.com/" target="_blank"
                    >Bootstrap</a
                  ></strong
                >: Styled web pages for the web app.
              </li>
            </ul>
          </div>

          <h4 id="step7">
            7Ô∏è‚É£ Upgrading UX/UI, Implementing Webhooks & User Notifications
          </h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Enhance UX/UI, implement a more robust approach for processing
              messages from a queue and apply asynchronous communication to the
              application by implementing a notifications service.
            </p>

            <h5>Demo Page</h5>
            <div class="is-flex is-flex-direction-row is-align-items-baseline">
              <figure class="image is-half">
                <image src="./img/gas.png" />
              </figure>
              <figure class="image is-half">
                <image src="./img/gas-1.png" />
              </figure>
            </div>

            <h5>Approach</h5>
            <h6>User Interface</h6>
            <ul>
              <li>
                Add a route handler that displays a list of all the jobs
                submitted by a user.
              </li>
              <li>
                Add a route handler that displays the details of a requested
                job. The page should be rendered in response to a request.
              </li>
              <li>
                Provide links for users to download the results file and view
                the log file for a job.
              </li>
            </ul>
            <h6>Implement webhooks</h6>
            <ul>
              <li><strong>Why?</strong></li>
              <p>
                Requiring the annotator to continuously poll the job requests
                queue is not good (scalable) application design. A better way is
                to use a webhook: an HTTP endpoint that is called by the
                producer when an event of interest to the consumer occurs (in
                our case, when a new job is available). Fortunately, SNS allows
                us to send a notification to an HTTP endpoint (in addition to
                SQS queues and other subscribers).
                <a
                  href="https://docs.aws.amazon.com/sns/latest/dg/sns-subscribe-https-s-endpoints-to-topic.html"
                  target="_blank"
                  >Checkout the AWS documentation</a
                >.
              </p>
              <li><strong>How?</strong></li>
              <p>
                Convert annotator.py to a Flask app with a route handler that
                acts as a webhook. The annotator will no longer continuously
                poll for job request messages; instead, it will do its work only
                when it receives a notification from SNS that a job was added to
                the job request queue. This requires adding the webhook as a
                subscriber to your SNS job request topic. When a new job is
                submitted, SNS will push the notification as a POST request to
                the webhook, triggering the annotation.
                <a href="#webhook-vs-polling"
                  >Checkout the difference between data polling and a webhook</a
                >.
              </p>
            </ul>

            <h6>User Notifications</h6>
            <p>
              Publishing a notification to an SNS topic (with a subscribed SQS
              queue, as we have for job requests) and running a separate Python
              script that sends emails to users. This way, the annotator can
              continue to process jobs while notifications for completed jobs
              are sent out-of-band. In order to send email, we will use the
              <a href="https://aws.amazon.com/ses/" target="_blank"
                >AWS SES service</a
              >.
            </p>
          </div>
          <h4>
            8Ô∏è‚É£ Data Archival:
            <a
              href="https://aws.amazon.com/s3/storage-classes/glacier/"
              target="_blank"
              >AWS S3 Glacier</a
            >
          </h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Understand the complexities of implementing scheduled/background
              tasks in distributed systems.
            </p>
            <h5>Approach</h5>
            <p>
              The policy for this service is that Free users can only download
              their results file for up to 5 minutes after completion of their
              annotation job. After 5 minutes elapse, a free user‚Äôs results file
              (not the log file) will be archived to a Glacier vault. This
              allows the service to retain user data at relatively low cost, and
              to restore it in the event that the user decides to upgrade to a
              Premium user.
            </p>
            <h5>
              Integrating
              <a href="https://aws.amazon.com/step-functions/" target="_blank"
                >AWS Step Functions</a
              >
              and
              <a href="https://aws.amazon.com/lambda/" target="_blank"
                >AWS Lambda</a
              >
            </h5>
            <ul>
              <li>
                I used step function to trigger a lambda function to wait for 5
                minutes after the file is annotated.
              </li>
              <li>
                The step function workflow is defined in
                <i>step_function.json</i>:
              </li>

              <script src="https://gist.github.com/Willie-The-Lord/884115de5ae1d65ce4dd59ecaf9f60bc.js"></script>

              <li>
                After 5 minutes, the lambda function will publish a message to
                SNS topic.
              </li>
              <li>
                Then the /archive endpoint will accept the POST requests from my
                SNS topic and then retrieve and process an archival message from
                my message queue.
              </li>
              <li>
                Then, the logic in archive_app.py will determine if the user is
                a premium user or not.
              </li>
              <li>
                If the user is a premium user, the file will not be archived.
              </li>
              <li>Otherwise, the file will be archived.</li>
            </ul>
            <h5>My rationale of this approach</h5>
            <ul>
              <li>
                <strong>Using Lambda rather than EC2</strong>
                <ul>
                  <li>
                    With Lambda, I only need to pay for the execution time of my
                    function. In this case, the function is only triggered after
                    the file is annotated, and it waits for 5 minutes before
                    publishing a message to the SNS topic. Therefore, I only
                    billed for the execution time of the Lambda function, which
                    is typically a few milliseconds.
                  </li>
                  <li>
                    If I use an EC2 instance or any other compute service to
                    perform the wait state, I would need to pay for the entire
                    duration of the wait time, which could be costly depending
                    on the duration of the wait state. Additionally, I would
                    need to manage and maintain the compute infrastructure,
                    which requires additional resources and effort.
                  </li>
                  <li>
                    Another benefit of using Lambda is scalability. AWS Lambda
                    automatically scales my function to handle incoming
                    requests, so I don't need to worry about provisioning and
                    scaling infrastructure. This allows me to handle sudden
                    spikes in traffic or increased workload without affecting
                    the performance of my application.
                  </li>
                </ul>
              </li>
              <li>
                <strong>Using step function to trigger lambda function</strong>
                <ul>
                  <li>
                    The main purpose is based on the coordination of workflow:
                    Using Step Functions to trigger a Lambda function allows me
                    to create a coordinated workflow that involves multiple
                    steps. In this case, I can use Step Functions to orchestrate
                    the entire process of archiving the file, including the wait
                    state, sending messages to SNS, and triggering the archive
                    process. This ensures that each step is executed in the
                    correct order, and the entire workflow is completed
                    successfully.
                  </li>
                </ul>
              </li>
              <li>
                <strong>Using SNS to notify the /archive endpoint</strong>
                <ul>
                  <li>
                    The use of SNS topic to notify the /archive endpoint to run
                    archive_free_user_data function provides a loosely coupled
                    architecture, which is a key principle for scalability.
                    Decoupling the process of archiving from the annotation
                    process ensures that any changes or scaling issues with one
                    process do not affect the other.
                  </li>
                </ul>
              </li>
            </ul>
          </div>

          <h4>
            9Ô∏è‚É£ Subscription Upgrade (Stripe Integration) & Data Restoration
          </h4>
          <div class="box">
            <h5>Objectives</h5>
            <p>
              Explore the requirements of integrating with a third-party SaaS
              system and understand the complexities of working with cloud
              archival systems and experiment with serverless computing.
            </p>
            <h5>Approach</h5>
            <h6>Stripe API</h6>
            <p>
              I integrate the
              <a href="https://stripe.com/" target="_blank">Stripe service</a>
              to manage all subscription and billing functions for this service.
              One of the main reason is: Stripe has one of the best
              <a hred="https://stripe.com/docs/api" target="_blank"
                >API documentation</a
              >
              of any SaaS.
            </p>
            <h6>Thawing / Restoring Work Flow</h6>
            <ul>
              <li>
                <strong>Thaw Webhook:</strong> I configure a thaw webhook to
                receive a request for restoring data from Glacier. This webhook
                will initiate the job to retrieve the archive from Glacier.
              </li>
              <li>
                <strong>Retrieval Job:</strong> Once the thaw webhook receives
                the request, it triggers a process to initiate a retrieval job
                from Glacier using the archive ID. This job retrieves the
                archived data from Glacier.
              </li>
              <li>
                <strong>SNS Notification:</strong> When the retrieval job is
                successfully completed, Glacier sends a notification to an SNS
                topic.
              </li>
              <li>
                <strong>Lambda Function:</strong> Set up a Lambda function that
                is triggered by the SNS topic when it receives the success
                message.
              </li>
              <li>
                <strong>Lambda Execution:</strong> In the Lambda function, parse
                the message received from the SNS topic to extract relevant
                information such as the archive ID, job ID, and S3 key file
                path.
              </li>
              <li>
                <strong>Retrieve Output Job:</strong> Use the job ID obtained
                from the message to fetch the output of the retrieval job. This
                output contains the restored data.
              </li>
              <li>
                <strong></strong>Store Data in S3: Upload the restored data to
                the designated S3 result bucket using the S3 key file path.
              </li>
              <li>
                <strong>Delete Archive Job:</strong> Delete the retrieval job
                from Glacier to clean up the resources and prevent unnecessary
                storage costs.
              </li>
              <li>
                <strong>DynamoDB Update:</strong> Remove the attribute named
                "results_file_archive_id" from the corresponding DynamoDB entry
                to reflect the completion of the restoration process.
              </li>
            </ul>
          </div>
          <h4>üîü Scaling the Web Server: ELB & Auto Scaling</h4>

          <div class="box">
            <h5>Objectives</h5>
            <p>
              Experiment with automated provisioning and elasticity in a cloud
              computing environment.
            </p>

            <h5 id="step10-diagram">Diagram</h5>
            <div
              class="is-flex is-justify-content-center is-align-items-center"
            >
              <figure class="image column is-two-thirds">
                <image src="./img/step10.jpg" />
              </figure>
            </div>
            <h5>Services</h5>
            <ul>
              <li>
                <strong>Elastic Load Balancer (ELB):</strong> This service
                allows HTTP(S) requests to be distributed among multiple
                instances in an Auto Scaling group. Checkout the
                <a
                  href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html"
                  target="_blank"
                  >AWS documentation</a
                >.
              </li>
              <li>
                <strong>EC2 Auto Scaling:</strong> This service allows us to
                define standard configuration templates and use them to launch
                multiple instances as needed, based on user-definable rules.
                Checkout the
                <a
                  href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html"
                  target="_blank"
                  >AWS documentation</a
                >.
              </li>
            </ul>
            <h5>Approach</h5>
            <ul>
              <li>
                <strong
                  >Create a load balancer and associated target group:</strong
                >
                An EC2 load balancer will receive all requests to this service
                and distribute them among multiple EC2 instances running the web
                server.
              </li>
              <li>
                <strong>Create a Launch Template:</strong> Launch template
                provide a means to save your standard EC2 instance launch
                procedure so that it can be used by the auto scaler when
                launching new instances.
              </li>
              <li>
                <strong>Create an Auto Scaling Group:</strong> Auto Scaling
                groups encapsulate the rules that determine how our application
                scales out (when demand increases) and in (when demand drops).
              </li>
            </ul>
          </div>
        </div>

        <div class="content pt-4">
          <h2>üÜö Different Approach</h2>
          <h4 id="webhook-vs-polling">Webhook vs. Data Polling</h4>
          <div class="box"></div>
          <h4>t3.nano vs. c5.2xlarge vs. r5.2xlarge</h4>
          <div class="box"></div>
        </div>

        <div class="content pt-4">
          <h2>üìù Key Feature</h2>
          <div class="box">
            <p>
              ‚úÖ Delivered <strong>complete and detailed</strong> annotation
              results through an easy-to-use panel.
            </p>
            <p>
              ‚úÖ Optimized scaling and load balancing for
              <strong>high-throughput</strong>
              genomics annotation tasks.
            </p>
            <p>
              ‚úÖ Offered <strong>subscription tiers</strong> with varying
              features and performance.
            </p>
          </div>
        </div>

        <div class="content pt-4">
          <h2>üíª Source Code</h2>
          <div class="is-flex">
            <div class="is-flex is-align-items-center mr-2">
              <p>Require GitLab permission:</p>
            </div>
            <a
              href="mailto:sungjiehung@gmail.com?subject=„ÄêGenomics Analysis Service„ÄëSource Code Request&body=üåüOnly for potential employers and recruiters"
              target="_blank"
              ><button class="button">
                <span class="icon">
                  <img
                    src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/gitlab/gitlab-original.svg"
                  />
                </span>
                <span>GitLab</span>
              </button></a
            >
          </div>
        </div>

        <div class="content pt-4">
          <h2>‚ö†Ô∏è Disclaimer</h2>

          <div class="box">
            <p>
              This is a UChicago MPCS<a
                href="https://mpcs-courses.cs.uchicago.edu/2022-23/spring/courses/mpcs-51083-1"
                target="_blank"
              >
                Cloud Computing Capstone Project</a
              >. ¬© 2023
              <a href="http://home.uchicago.edu/vas/" target="_blank"
                >Vas Vasiliadis</a
              >, All rights reserved.
            </p>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="content has-text-centered">
        <p>
          Written by
          <strong
            ><a href="https://sungjiehung.com/" target="_blank"
              >Sung-Jie Hung</a
            ></strong
          >
          ‚ù§Ô∏è
        </p>
        <p>Last update: <strong>Jul 7, 2023</strong></p>
      </div>
    </footer>

    <script
      src="https://kit.fontawesome.com/7119540adb.js"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
